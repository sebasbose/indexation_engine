# Notas de Implementaci√≥n

## ‚úÖ Completado - D√≠a 0 (7 de noviembre)

### Estructura del Proyecto
El proyecto ha sido completamente estructurado y configurado como un monorepo con los siguientes componentes:

#### 1. Infraestructura (Docker Compose)
- **Kafka + Zookeeper**: Sistema de mensajer√≠a para procesamiento as√≠ncrono
- **MySQL**: Almacenamiento de metadatos (url, title, description, keywords)
- **PostgreSQL**: √çndice invertido para b√∫squedas eficientes
- **MongoDB**: Almacenamiento de contenido completo

#### 2. Servicios de Aplicaci√≥n

**Crawler (services/crawler/)**
- Framework: Scrapy (Python)
- Funcionalidad:
  - Crawlea p√°ginas web desde lista de seeds
  - Extrae: t√≠tulo, meta-description, keywords, contenido
  - Env√≠a datos a Kafka (topic: pages.raw)
- Configuraci√≥n:
  - L√≠mite: 500 p√°ginas (CLOSESPIDER_PAGECOUNT)
  - Delay: 0.5s entre requests
  - AutoThrottle habilitado
  - Respeta robots.txt

**Ingest Service (services/ingest/)**
- Lenguaje: Python
- Funcionalidad:
  - Consume mensajes de Kafka
  - Tokeniza contenido (lowercase, remove punctuation)
  - Almacena en 3 bases de datos simult√°neamente
  - Crea √≠ndice invertido (token ‚Üí document_id ‚Üí frequency)
- Caracter√≠sticas:
  - Auto-reconexi√≥n a bases de datos
  - Inicializaci√≥n autom√°tica de esquemas
  - Manejo robusto de errores

**API Gateway (services/api/)**
- Framework: Node.js + Express
- Funcionalidad:
  - Endpoint `/api/search`: b√∫squeda distribuida
  - Endpoint `/api/stats`: estad√≠sticas del sistema
  - Endpoint `/api/health`: verificaci√≥n de salud
- Algoritmo de b√∫squeda:
  1. Tokeniza query
  2. Consulta PostgreSQL para encontrar documentos con tokens
  3. Obtiene metadata de MySQL
  4. Obtiene snippets de MongoDB
  5. Agrega y ordena por score (sum de frequencies)
- CORS habilitado para desarrollo

**Web Frontend (services/web/)**
- Framework: Next.js + React
- Caracter√≠sticas:
  - Interfaz limpia y moderna
  - B√∫squeda en tiempo real
  - Visualizaci√≥n de resultados con snippets
  - Estad√≠sticas del sistema
  - Dise√±o responsive

#### 3. Documentaci√≥n
- `README.md`: Gu√≠a principal
- `docs/QUICKSTART.md`: Inicio r√°pido
- `docs/arquitectura.md`: Arquitectura detallada
- `docs/PLAN_DE_TRABAJO.md`: Roadmap de 3 d√≠as
- `docs/DEBUGGING.md`: Comandos √∫tiles
- `docs/RESUMEN_EJECUTIVO.md`: Resumen del proyecto

#### 4. Scripts y Utilidades
- `manage.sh`: Script bash para gesti√≥n del sistema
- `Makefile`: Comandos make para tareas comunes
- `.env.example`: Template de variables de entorno
- `.gitignore`: Archivos a ignorar en git

---

## üéØ Decisiones de Dise√±o

### Almacenamiento Distribuido

**MySQL - Metadatos Relacionales**
- Ventaja: Consultas relacionales eficientes, integridad referencial
- Uso: Almacenar informaci√≥n estructurada (url, title, description, etc.)
- Esquema: Tabla `documents` con √≠ndices en document_id

**PostgreSQL - √çndice Invertido**
- Ventaja: Excelente soporte para √≠ndices complejos, JSONB para metadata
- Uso: √çndice invertido (token ‚Üí document_id ‚Üí frequency)
- Esquema: Tabla `inverted_index` con √≠ndices en token y document_id
- Optimizaci√≥n: UNIQUE constraint en (token, document_id) evita duplicados

**MongoDB - Contenido No Estructurado**
- Ventaja: Flexible, eficiente para documentos grandes
- Uso: Almacenar contenido completo de p√°ginas
- Esquema: Colecci√≥n `documents` con campos flexibles

### Procesamiento As√≠ncrono con Kafka

**¬øPor qu√© Kafka?**
- Desacoplamiento: Crawler y ingest pueden escalar independientemente
- Resiliencia: Si ingest falla, mensajes se mantienen en cola
- Paralelizaci√≥n: M√∫ltiples consumers pueden procesar en paralelo

**Topic Design**
- `pages.raw`: P√°ginas crawleadas (key: document_id)
- Particionamiento futuro: Por dominio o hash de URL

### Tokenizaci√≥n Simple

**Algoritmo Actual**
1. Lowercase del texto
2. Remover puntuaci√≥n (regex: `[^\w\s]`)
3. Split por espacios
4. Filtrar tokens < 3 caracteres

**Mejoras Futuras**
- Stemming (porter stemmer)
- Stop words removal
- Normalizaci√≥n de acentos
- N-gramas para mejores b√∫squedas

### Scoring B√°sico

**Algoritmo Actual**
- Score = SUM(frequency) para todos los tokens de la query
- Ordenar por score DESC

**Mejoras Futuras**
- TF-IDF (Term Frequency - Inverse Document Frequency)
- BM25 ranking
- PageRank para autoridad
- Boost por recency (p√°ginas m√°s recientes)

---

## üìä Modelo de Datos

### MySQL Schema
```sql
CREATE TABLE documents (
    id INT AUTO_INCREMENT PRIMARY KEY,
    document_id VARCHAR(255) UNIQUE NOT NULL,
    url TEXT NOT NULL,
    title TEXT,
    description TEXT,
    keywords TEXT,
    crawl_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    source VARCHAR(255),
    INDEX idx_document_id (document_id)
);
```

### PostgreSQL Schema
```sql
CREATE TABLE inverted_index (
    id SERIAL PRIMARY KEY,
    token VARCHAR(255) NOT NULL,
    document_id VARCHAR(255) NOT NULL,
    frequency INT DEFAULT 1,
    positions JSONB,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(token, document_id)
);

CREATE INDEX idx_token ON inverted_index(token);
CREATE INDEX idx_document_id ON inverted_index(document_id);
```

### MongoDB Schema (flexible)
```javascript
{
  document_id: String,
  url: String,
  content: String,
  title: String,
  crawl_timestamp: Date
}
```

---

## üîß Configuraciones Importantes

### Docker Compose
- Network: `search-network` (bridge)
- Vol√∫menes persistentes para todas las DBs
- Healthchecks: Configurar en pr√≥xima iteraci√≥n
- Restart policy: Configurar en producci√≥n

### Variables de Entorno
Todas definidas en docker-compose.yml:
- Kafka: KAFKA_BOOTSTRAP_SERVERS, KAFKA_TOPIC
- MySQL: MYSQL_HOST, MYSQL_USER, MYSQL_PASSWORD, MYSQL_DATABASE
- PostgreSQL: POSTGRES_HOST, POSTGRES_USER, POSTGRES_PASSWORD, POSTGRES_DATABASE
- MongoDB: MONGODB_URI

### Puertos Expuestos
- Web UI: 3000
- API: 3001
- MySQL: 3306
- PostgreSQL: 5432
- MongoDB: 27017
- Kafka: 9092
- Zookeeper: 2181

---

## ‚ö° Performance Consideraciones

### Crawling
- Throughput esperado: 50-100 p√°ginas/minuto
- Depende de: delay configurado, velocidad de respuesta de sitios
- Limitado por: ROBOTSTXT_OBEY, DOWNLOAD_DELAY

### Indexaci√≥n
- Throughput esperado: 50+ documentos/segundo
- Depende de: velocidad de escritura de DBs, complejidad de tokenizaci√≥n
- Limitado por: velocidad de Kafka consumer, latencia de red

### B√∫squedas
- Latencia esperada: < 200ms (p95)
- Depende de: n√∫mero de tokens en query, tama√±o del √≠ndice
- Optimizaci√≥n: √çndices en PostgreSQL son cruciales

---

## üö® Limitaciones Conocidas

1. **No hay autenticaci√≥n**: Sistema abierto, no hay control de acceso
2. **Scoring simple**: No usa TF-IDF ni algoritmos avanzados
3. **Sin paginaci√≥n completa**: Implementaci√≥n b√°sica
4. **No hay caching**: Cada b√∫squeda consulta las bases de datos
5. **Sin monitoring avanzado**: Solo logs y endpoints b√°sicos
6. **Replicaci√≥n no implementada**: Simular en D√≠a 2
7. **Sin rate limiting**: API puede ser sobrecargada

---

## üéì Conceptos Clave del Proyecto

### Distribuci√≥n
- **Fragmentaci√≥n horizontal**: Datos divididos en m√∫ltiples nodos
- **Especializaci√≥n por tipo de dato**: Cada DB optimizada para su uso
- **Consulta distribuida**: API agrega resultados de m√∫ltiples fuentes

### Consistencia
- **Eventual consistency**: Ventana entre crawl y disponibilidad en b√∫squeda
- **No hay transacciones distribuidas**: Cada DB se actualiza independientemente
- **Trade-off aceptado**: Prioriza availability sobre strict consistency

### Tolerancia a Fallos
- **Partial results**: API contin√∫a si una DB falla
- **Kafka como buffer**: Protege contra p√©rdida de datos si ingest falla
- **Retry logic**: Scrapy reintenta requests fallidos

---

## üìà M√©tricas de √âxito

### Funcionales
- ‚úÖ Crawlea 500+ p√°ginas
- ‚úÖ Almacena en 3 bases de datos
- ‚úÖ B√∫squedas retornan resultados relevantes
- ‚úÖ UI funcional y responsive

### No Funcionales
- ‚úÖ Latencia de b√∫squeda < 1s
- ‚úÖ Sistema se levanta en < 5 minutos
- ‚úÖ Documentaci√≥n completa
- ‚úÖ C√≥digo limpio y organizado

---

## üîú Pr√≥ximos Pasos (Para D√≠a 1)

1. **Levantar el sistema** y verificar que todo funciona
2. **Monitorear el crawling** y asegurar que se indexan p√°ginas
3. **Probar b√∫squedas** con diferentes queries
4. **Identificar y corregir bugs**
5. **Ajustar configuraci√≥n** si es necesario
6. **Documentar problemas encontrados**

---

## üí° Tips para la Demo

1. Preparar b√∫squedas de ejemplo con resultados conocidos
2. Mostrar estad√≠sticas antes/despu√©s de crawling
3. Demostrar tolerancia a fallos (detener un contenedor)
4. Explicar arquitectura con diagrama
5. Mostrar c√≥digo clave (spider, ingest, API)
6. Tener respuestas preparadas para preguntas comunes

---

## üìö Referencias

- Scrapy: https://docs.scrapy.org/
- Kafka: https://kafka.apache.org/documentation/
- PostgreSQL: https://www.postgresql.org/docs/
- MongoDB: https://docs.mongodb.com/
- Next.js: https://nextjs.org/docs

---

_Documento creado: 7 de noviembre, 2025_
_√öltima actualizaci√≥n: 7 de noviembre, 2025_
