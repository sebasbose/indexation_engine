# üé¨ Script de Demo para Presentaci√≥n

## Preparaci√≥n Pre-Demo (30 minutos antes)

```bash
# 1. Asegurarse de que todo est√© limpio
cd /Users/sebasbose/Desktop/indexation_engine
make clean

# 2. Levantar sistema desde cero
make start

# 3. Esperar 3-5 minutos para que indexe p√°ginas

# 4. Verificar que hay datos suficientes
make stats
# Debe mostrar: documents >= 100, tokens >= 1000

# 5. Verificar salud del sistema
make health
# Todos los servicios deben estar "connected"

# 6. Abrir pesta√±as del navegador (NO CERRAR)
# - http://localhost:3000 (Frontend)
# - Terminal con logs listos
```

---

## Demo Script (10-15 minutos)

### 1. Introducci√≥n (1 minuto)

**Decir:**
> "Desarrollamos un motor de b√∫squeda distribuido que indexa p√°ginas web y permite b√∫squedas eficientes. El sistema usa Kafka para procesamiento as√≠ncrono y almacena datos en 3 bases de datos especializadas."

**Mostrar:** Diapositiva con arquitectura

---

### 2. Arquitectura del Sistema (2 minutos)

**Decir:**
> "El sistema tiene 4 componentes principales: Crawler, Sistema de Mensajer√≠a, Almacenamiento Distribuido, y Frontend."

**Mostrar:** Diagrama de arquitectura (docs/DIAGRAMAS.md)

```
Crawler (Scrapy) ‚Üí Kafka ‚Üí Ingest Service ‚Üí 3 Bases de Datos
                                              ‚Üì
                                         API Gateway
                                              ‚Üì
                                          Frontend
```

**Explicar cada capa:**
1. **Crawler**: Scrapy extrae datos de p√°ginas web
2. **Kafka**: Cola de mensajes para procesamiento as√≠ncrono
3. **Almacenamiento**: 
   - MySQL: Metadatos (url, t√≠tulo, descripci√≥n)
   - PostgreSQL: √çndice invertido (tokens ‚Üí documentos)
   - MongoDB: Contenido completo
4. **API**: Agrega consultas de las 3 bases de datos
5. **Frontend**: Interfaz Next.js

---

### 3. Demo del Sistema Funcionando (3 minutos)

#### Mostrar Estad√≠sticas

```bash
# Terminal 1
curl -s http://localhost:3001/api/stats | jq
```

**Decir:**
> "Actualmente tenemos [X] documentos indexados con [Y] tokens √∫nicos en nuestro √≠ndice invertido."

#### Mostrar la UI

**Ir a:** http://localhost:3000

**Decir:**
> "Esta es nuestra interfaz web donde los usuarios pueden realizar b√∫squedas."

#### Realizar B√∫squeda de Demo

**B√∫squeda 1: "python"**

**Decir:**
> "Busquemos 'python'. El sistema tokeniza la query, consulta el √≠ndice en PostgreSQL, obtiene metadata de MySQL y snippets de MongoDB, y agrega los resultados ordenados por relevancia."

**Mostrar:** Resultados aparecen con t√≠tulo, URL, snippet y score

**B√∫squeda 2: "database systems"**

**Decir:**
> "Con queries de m√∫ltiples palabras, el sistema busca documentos que contengan cualquiera de los tokens y suma las frecuencias para calcular el score."

---

### 4. Mostrar el Proceso de Indexaci√≥n (2 minutos)

#### Ver logs del crawler

```bash
# Terminal 2
docker-compose logs --tail=20 crawler
```

**Decir:**
> "El crawler est√° constantemente visitando p√°ginas web. Aqu√≠ vemos las URLs que est√° procesando."

#### Ver logs del ingest

```bash
docker-compose logs --tail=20 ingest
```

**Decir:**
> "El servicio de ingest consume mensajes de Kafka y almacena los datos en las 3 bases de datos simult√°neamente."

---

### 5. Demostrar Consulta Distribuida (3 minutos)

#### Mostrar consulta a cada base de datos

**Terminal 3 - MySQL (Metadata):**
```bash
docker exec -it indexation_engine-mysql-1 mysql -u searchuser -psearchpass -e \
"SELECT url, title FROM searchdb.documents LIMIT 3;"
```

**Decir:**
> "MySQL almacena los metadatos estructurados de cada documento."

**Terminal 4 - PostgreSQL (√çndice):**
```bash
docker exec -it indexation_engine-postgres-1 psql -U searchuser -d indexdb -c \
"SELECT token, COUNT(*) as doc_count FROM inverted_index 
 WHERE token IN ('python', 'database', 'programming') 
 GROUP BY token ORDER BY doc_count DESC;"
```

**Decir:**
> "PostgreSQL mantiene el √≠ndice invertido que permite b√∫squedas r√°pidas. Aqu√≠ vemos cu√°ntos documentos contienen cada token."

**Terminal 5 - MongoDB (Contenido):**
```bash
docker exec -it indexation_engine-mongodb-1 mongosh -u root -p rootpass --quiet --eval \
"use contentdb; db.documents.findOne({}, {url: 1, content: 1, _id: 0})"
```

**Decir:**
> "MongoDB almacena el contenido completo de las p√°ginas para generar snippets."

---

### 6. Tolerancia a Fallos (2-3 minutos)

**IMPORTANTE:** Practica esto antes de la demo

#### Detener MySQL

```bash
docker-compose stop mysql
```

**Decir:**
> "Ahora voy a simular una falla del servidor MySQL para demostrar la tolerancia a fallos del sistema."

#### Verificar health

```bash
curl -s http://localhost:3001/api/health | jq
```

**Mostrar:** MySQL aparece como "disconnected", otros servicios OK

**Decir:**
> "El sistema detecta que MySQL est√° ca√≠do pero los otros servicios siguen funcionando."

#### Realizar b√∫squeda

**Ir a:** http://localhost:3000

**Buscar:** "python"

**Decir:**
> "A pesar de que MySQL est√° ca√≠do, el sistema puede seguir entregando resultados usando PostgreSQL para el √≠ndice y MongoDB para el contenido. La API marca el resultado como 'partial' para indicar que falta informaci√≥n."

#### Restaurar MySQL

```bash
docker-compose start mysql
# Esperar 10 segundos
curl -s http://localhost:3001/api/health | jq
```

**Decir:**
> "Una vez que restauramos el servicio, el sistema vuelve a su funcionamiento normal autom√°ticamente."

---

### 7. M√©tricas y Performance (1 minuto)

```bash
# Medir latencia de una b√∫squeda
time curl -s "http://localhost:3001/api/search?q=python" > /dev/null
```

**Decir:**
> "El tiempo de respuesta es de aproximadamente [X] milisegundos, lo cual es aceptable para este tipo de sistema."

```bash
# Mostrar estad√≠sticas finales
curl -s http://localhost:3001/api/stats | jq
```

**Decir:**
> "Hemos indexado [X] documentos con [Y] tokens √∫nicos, demostrando la capacidad del sistema para manejar grandes vol√∫menes de datos."

---

### 8. Conclusiones (1 minuto)

**Decir:**
> "En resumen, hemos implementado:
> 1. Un crawler distribuido que indexa p√°ginas web autom√°ticamente
> 2. Procesamiento as√≠ncrono con Kafka para desacoplar componentes
> 3. Almacenamiento especializado en 3 bases de datos diferentes
> 4. Un √≠ndice invertido eficiente para b√∫squedas r√°pidas
> 5. Tolerancia a fallos con resultados parciales
> 6. Una interfaz web moderna y funcional
>
> Todo el sistema est√° contenerizado con Docker y se puede desplegar con un solo comando."

---

## Preguntas Frecuentes (Preparar Respuestas)

### P: ¬øPor qu√© usar 3 bases de datos?

**R:** Cada base de datos est√° optimizada para un tipo de dato espec√≠fico:
- MySQL: Excelente para datos relacionales estructurados (metadata)
- PostgreSQL: Superior para √≠ndices complejos y b√∫squedas (√≠ndice invertido)
- MongoDB: Eficiente para documentos grandes no estructurados (contenido)

### P: ¬øC√≥mo se calcula el score de relevancia?

**R:** Actualmente usamos un algoritmo simple: sumamos las frecuencias de aparici√≥n de cada token de la query en el documento. En producci√≥n, implementar√≠amos TF-IDF o BM25 para mejores resultados.

### P: ¬øC√≥mo se escala el sistema?

**R:** Cada componente puede escalar horizontalmente:
- Crawler: M√∫ltiples instancias procesando diferentes URLs
- Ingest: Consumer group de Kafka para paralelismo
- API: Load balancer con m√∫ltiples instancias
- Bases de datos: Sharding y replicaci√≥n

### P: ¬øQu√© pasa si Kafka falla?

**R:** Kafka tiene persistencia en disco y replicaci√≥n. Si el broker falla temporalmente, los mensajes no se pierden. Cuando se recupera, el ingest contin√∫a procesando desde donde qued√≥.

### P: ¬øC√≥mo se maneja la consistencia?

**R:** Usamos eventual consistency. Hay una peque√±a ventana entre que se crawlea una p√°gina y est√° disponible para b√∫squeda. Esto es aceptable para este tipo de sistema.

### P: ¬øCu√°ntas p√°ginas puede manejar?

**R:** Con la arquitectura actual y configuraci√≥n b√°sica, podemos manejar f√°cilmente 10,000-100,000 documentos. Para escalar a millones, necesitar√≠amos:
- Sharding de las bases de datos
- M√∫ltiples particiones en Kafka
- Cache de resultados
- CDN para el frontend

---

## Checklist Pre-Demo

- [ ] Sistema levantado y estable (30 min antes)
- [ ] Al menos 100 documentos indexados
- [ ] Todas las bases de datos conectadas
- [ ] Pesta√±as del navegador abiertas
- [ ] Terminales preparadas con comandos
- [ ] Diapositivas listas
- [ ] Practica el flujo completo al menos 2 veces

---

## Comandos de Emergencia

### Si algo falla durante la demo:

```bash
# Reset r√°pido (2-3 minutos)
docker-compose restart

# Ver qu√© est√° fallando
docker-compose ps
docker-compose logs --tail=50

# Reiniciar servicio espec√≠fico
docker-compose restart [service-name]
```

---

## Tips de Presentaci√≥n

1. **Habla con confianza**: Conoces tu sistema mejor que nadie
2. **Explica el "por qu√©"**: No solo el "qu√©"
3. **Maneja los errores con gracia**: Si algo falla, explica c√≥mo lo solucionar√≠as
4. **Usa t√©rminos t√©cnicos correctamente**: Pero expl√≠calos si es necesario
5. **Mant√©n contacto visual**: No solo leas las diapositivas
6. **Responde preguntas directamente**: Si no sabes algo, di "No lo implementamos pero ser√≠a interesante considerarlo"
7. **Termina con tiempo para preguntas**: Deja al menos 5 minutos

---

## Timing Sugerido

- Introducci√≥n: 1 min
- Arquitectura: 2 min
- Demo UI: 3 min
- Proceso de indexaci√≥n: 2 min
- Consulta distribuida: 3 min
- Tolerancia a fallos: 2-3 min
- M√©tricas: 1 min
- Conclusiones: 1 min
- **Total: 15 minutos**
- Preguntas: 5-10 minutos

---

## Plan B (Si la demo en vivo falla)

1. **Tener screenshots preparados** de cada paso
2. **Tener un video grabado** del sistema funcionando
3. **Explicar con diagramas** c√≥mo funcionar√≠a
4. **Mostrar el c√≥digo** en lugar de ejecuci√≥n

---

_¬°√âxito en tu presentaci√≥n!_
